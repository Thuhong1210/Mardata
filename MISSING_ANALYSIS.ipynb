{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üìä PH√ÇN T√çCH B·ªî SUNG - MDA2025\n",
                "\n",
                "**3 ph√¢n t√≠ch c√≤n thi·∫øu:**\n",
                "1. Data Cleaning\n",
                "2. Factor Analysis\n",
                "3. Regression Analysis\n",
                "\n",
                "---\n",
                "\n",
                "## üìå H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG\n",
                "\n",
                "### Option A: Ch·∫°y notebook n√†y ri√™ng\n",
                "1. Upload file `onlinebuy.csv`\n",
                "2. Ch·∫°y Cell 0 ƒë·ªÉ ƒë·ªçc d·ªØ li·ªáu\n",
                "3. Ch·∫°y Cell 1, 2, 3 theo th·ª© t·ª±\n",
                "\n",
                "### Option B: Copy v√†o notebook ch√≠nh\n",
                "1. M·ªü `Ph√¢n_t√≠ch_marketing_UPDATED.ipynb`\n",
                "2. T√¨m v·ªã tr√≠ sau cell ƒë·ªçc d·ªØ li·ªáu\n",
                "3. Copy Cell 1, 2, 3 t·ª´ ƒë√¢y\n",
                "4. Paste v√†o notebook ch√≠nh"
            ],
            "metadata": {
                "id": "header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# ============================================================\n",
                "# CELL 0: ƒê·ªåC D·ªÆ LI·ªÜU (ch·ªâ c·∫ßn n·∫øu ch·∫°y notebook n√†y ri√™ng)\n",
                "# ============================================================\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# ƒê·ªçc d·ªØ li·ªáu\n",
                "df = pd.read_csv('onlinebuy.csv')\n",
                "print(f\"K√≠ch th∆∞·ªõc d·ªØ li·ªáu g·ªëc: {df.shape}\")\n",
                "df.head()"
            ],
            "metadata": {
                "id": "load_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# ============================================================\n",
                "# CELL 1: DATA CLEANING\n",
                "# ============================================================\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(\"üßπ B∆Ø·ªöC 1: DATA CLEANING\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# Danh s√°ch c√°c c·ªôt Likert c·∫ßn ki·ªÉm tra\n",
                "likert_cols = [\n",
                "    'int1','int2','inf1','inf2','inf3','ve1','ve2','ve3','nvse1','nvse2',\n",
                "    'trust1','trust2','trust3','conv1','conv2','conv3','conv4',\n",
                "    'enj1','enj2','enj3','sc1','sc2','al1','al2','al3'\n",
                "]\n",
                "\n",
                "def check_invalid(row):\n",
                "    \"\"\"\n",
                "    Ki·ªÉm tra d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá:\n",
                "    1. T·∫•t c·∫£ gi√° tr·ªã gi·ªëng nhau\n",
                "    2. ‚â•10 gi√° tr·ªã li√™n ti·∫øp gi·ªëng nhau\n",
                "    \"\"\"\n",
                "    vals = row[likert_cols].values\n",
                "    \n",
                "    # Ki·ªÉm tra t·∫•t c·∫£ gi·ªëng nhau\n",
                "    if len(set(vals)) == 1:\n",
                "        return True\n",
                "    \n",
                "    # Ki·ªÉm tra 10 li√™n ti·∫øp gi·ªëng nhau\n",
                "    max_c = current = 1\n",
                "    for i in range(1, len(vals)):\n",
                "        if vals[i] == vals[i-1]:\n",
                "            current += 1\n",
                "            max_c = max(max_c, current)\n",
                "        else:\n",
                "            current = 1\n",
                "    return max_c >= 10\n",
                "\n",
                "# T√¨m v√† lo·∫°i b·ªè d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá\n",
                "print(f\"\\nüîç Ki·ªÉm tra d·ªØ li·ªáu...\")\n",
                "invalid = [i for i, row in df.iterrows() if check_invalid(row)]\n",
                "\n",
                "print(f\"\\nüìä K·∫æT QU·∫¢:\")\n",
                "print(f\"   T·ªïng m·∫´u ban ƒë·∫ßu: {len(df)}\")\n",
                "print(f\"   M·∫´u kh√¥ng h·ª£p l·ªá: {len(invalid)} ({len(invalid)/len(df)*100:.1f}%)\")\n",
                "\n",
                "if len(invalid) > 0:\n",
                "    print(f\"\\n   V√≠ d·ª• 5 m·∫´u ƒë·∫ßu ti√™n b·ªã lo·∫°i: {invalid[:5]}\")\n",
                "\n",
                "# Lo·∫°i b·ªè\n",
                "df = df.drop(invalid).reset_index(drop=True)\n",
                "\n",
                "print(f\"\\n‚úÖ SAU KHI L√ÄM S·∫†CH:\")\n",
                "print(f\"   C√≤n l·∫°i: {len(df)} m·∫´u ({len(df)/(len(df)+len(invalid))*100:.1f}%)\")\n",
                "print(f\"   ƒê√£ lo·∫°i: {len(invalid)} m·∫´u\")\n",
                "\n",
                "# L∆∞u d·ªØ li·ªáu s·∫°ch\n",
                "df.to_csv('onlinebuy_cleaned.csv', index=False)\n",
                "print(f\"\\nüíæ ƒê√£ l∆∞u: onlinebuy_cleaned.csv\")"
            ],
            "metadata": {
                "id": "data_cleaning"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# ============================================================\n",
                "# CELL 2: FACTOR ANALYSIS\n",
                "# ============================================================\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"üìä B∆Ø·ªöC 2: FACTOR ANALYSIS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "# C√†i ƒë·∫∑t th∆∞ vi·ªán\n",
                "!pip install factor-analyzer -q\n",
                "\n",
                "from factor_analyzer import FactorAnalyzer\n",
                "from factor_analyzer.factor_analyzer import calculate_kmo, calculate_bartlett_sphericity\n",
                "\n",
                "# KMO Test\n",
                "print(\"\\nüîç KMO & Bartlett's Test:\")\n",
                "kmo_all, kmo = calculate_kmo(df[likert_cols])\n",
                "print(f\"\\n   KMO Score: {kmo:.3f}\")\n",
                "\n",
                "if kmo >= 0.9:\n",
                "    print(f\"   ‚Üí ‚úÖ Tuy·ªát v·ªùi (‚â•0.9)\")\n",
                "elif kmo >= 0.8:\n",
                "    print(f\"   ‚Üí ‚úÖ R·∫•t t·ªët (‚â•0.8)\")\n",
                "elif kmo >= 0.7:\n",
                "    print(f\"   ‚Üí ‚úÖ Trung b√¨nh (‚â•0.7)\")\n",
                "elif kmo >= 0.6:\n",
                "    print(f\"   ‚Üí ‚ö†Ô∏è  V·ª´a ph·∫£i (‚â•0.6)\")\n",
                "else:\n",
                "    print(f\"   ‚Üí ‚ùå Kh√¥ng ph√π h·ª£p (<0.6)\")\n",
                "\n",
                "# Bartlett's Test\n",
                "chi2, pval = calculate_bartlett_sphericity(df[likert_cols])\n",
                "print(f\"\\n   Bartlett's Test:\")\n",
                "print(f\"     Chi-square: {chi2:.2f}\")\n",
                "print(f\"     p-value: {pval:.4f}\")\n",
                "if pval < 0.05:\n",
                "    print(f\"   ‚Üí ‚úÖ C√≥ √Ω nghƒ©a (p < 0.05)\")\n",
                "else:\n",
                "    print(f\"   ‚Üí ‚ùå Kh√¥ng c√≥ √Ω nghƒ©a (p ‚â• 0.05)\")\n",
                "\n",
                "# X√°c ƒë·ªãnh s·ªë nh√¢n t·ªë t·ªëi ∆∞u\n",
                "print(\"\\nüîç X√°c ƒë·ªãnh s·ªë nh√¢n t·ªë:\")\n",
                "fa_test = FactorAnalyzer(n_factors=25, rotation=None)\n",
                "fa_test.fit(df[likert_cols])\n",
                "ev, v = fa_test.get_eigenvalues()\n",
                "n_factors = sum(ev > 1.0)\n",
                "print(f\"\\n   S·ªë nh√¢n t·ªë c√≥ eigenvalue > 1.0: {n_factors}\")\n",
                "print(f\"\\n   Top 10 Eigenvalues:\")\n",
                "for i, eigenvalue in enumerate(ev[:10], 1):\n",
                "    marker = \"‚úÖ\" if eigenvalue > 1.0 else \"  \"\n",
                "    print(f\"   {marker} Factor {i}: {eigenvalue:.3f}\")\n",
                "\n",
                "# Ch·∫°y Factor Analysis v·ªõi Varimax\n",
                "print(f\"\\nüîç Factor Analysis v·ªõi {n_factors} factors (Varimax Rotation):\")\n",
                "fa = FactorAnalyzer(n_factors=n_factors, rotation='varimax')\n",
                "fa.fit(df[likert_cols])\n",
                "\n",
                "# Factor Loadings\n",
                "loadings_df = pd.DataFrame(\n",
                "    fa.loadings_,\n",
                "    index=likert_cols,\n",
                "    columns=[f'Factor{i+1}' for i in range(n_factors)]\n",
                ")\n",
                "\n",
                "print(\"\\nüìã Factor Loadings (ch·ªâ hi·ªÉn th·ªã |loading| ‚â• 0.4):\")\n",
                "for col in loadings_df.columns:\n",
                "    high = loadings_df[col][abs(loadings_df[col]) >= 0.4].sort_values(ascending=False)\n",
                "    if len(high) > 0:\n",
                "        print(f\"\\n   {col}:\")\n",
                "        for var, val in high.items():\n",
                "            print(f\"     {var:8s}: {val:6.3f}\")\n",
                "\n",
                "# Variance Explained\n",
                "variance = fa.get_factor_variance()\n",
                "print(f\"\\nüìä Variance Explained:\")\n",
                "print(f\"   T·ªïng ph∆∞∆°ng sai gi·∫£i th√≠ch: {variance[2][-1]*100:.1f}%\")\n",
                "\n",
                "# L∆∞u k·∫øt qu·∫£\n",
                "loadings_df.to_csv('factor_loadings.csv')\n",
                "print(f\"\\nüíæ ƒê√£ l∆∞u: factor_loadings.csv\")\n",
                "\n",
                "# Hi·ªÉn th·ªã to√†n b·ªô loadings matrix\n",
                "print(\"\\nüìã FULL FACTOR LOADINGS MATRIX:\")\n",
                "display(loadings_df.round(3))"
            ],
            "metadata": {
                "id": "factor_analysis"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# ============================================================\n",
                "# CELL 3: REGRESSION ANALYSIS\n",
                "# ============================================================\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"üìà B∆Ø·ªöC 3: REGRESSION ANALYSIS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "import statsmodels.api as sm\n",
                "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
                "\n",
                "# T·∫°o bi·∫øn AL (Attitudinal Loyalty)\n",
                "print(\"\\nüîß T·∫°o bi·∫øn AL (Attitudinal Loyalty)...\")\n",
                "df['AL'] = df[['al1','al2','al3']].mean(axis=1)\n",
                "print(f\"   ‚úÖ AL = mean(al1, al2, al3)\")\n",
                "print(f\"   Mean AL: {df['AL'].mean():.3f}\")\n",
                "print(f\"   Std AL: {df['AL'].std():.3f}\")\n",
                "\n",
                "# ============================================================\n",
                "# REGRESSION 1: Platform Features ‚Üí Attitudinal Loyalty\n",
                "# ============================================================\n",
                "\n",
                "print(\"\\n\" + \"-\"*80)\n",
                "print(\"üìä REGRESSION 1: Platform Features ‚Üí Attitudinal Loyalty\")\n",
                "print(\"-\"*80)\n",
                "\n",
                "# Bi·∫øn ƒë·ªôc l·∫≠p: Platform characteristics\n",
                "X1_vars = ['INT', 'INF', 'VE', 'NVSE']\n",
                "X1 = df[X1_vars]\n",
                "y = df['AL']\n",
                "\n",
                "# Th√™m constant\n",
                "X1_const = sm.add_constant(X1)\n",
                "\n",
                "# Ch·∫°y OLS\n",
                "m1 = sm.OLS(y, X1_const).fit()\n",
                "\n",
                "print(f\"\\nüìà K·∫æT QU·∫¢ MODEL 1:\")\n",
                "print(f\"   R¬≤ = {m1.rsquared:.4f}\")\n",
                "print(f\"   Adjusted R¬≤ = {m1.rsquared_adj:.4f}\")\n",
                "print(f\"   F-statistic = {m1.fvalue:.4f} (p = {m1.f_pvalue:.4f})\")\n",
                "\n",
                "print(f\"\\n   Coefficients:\")\n",
                "for var in ['const'] + X1_vars:\n",
                "    coef = m1.params[var]\n",
                "    pval = m1.pvalues[var]\n",
                "    sig = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \"\"\n",
                "    print(f\"     {var:8s}: {coef:7.4f}  (p = {pval:.4f}) {sig}\")\n",
                "\n",
                "print(f\"\\n   Ghi ch√∫: *** p<0.001, ** p<0.01, * p<0.05\")\n",
                "\n",
                "# VIF Check\n",
                "print(f\"\\n   üîç VIF (Multicollinearity Check):\")\n",
                "vif_data1 = pd.DataFrame()\n",
                "vif_data1[\"Variable\"] = X1_vars\n",
                "vif_data1[\"VIF\"] = [variance_inflation_factor(X1.values, i) for i in range(len(X1_vars))]\n",
                "print(vif_data1.to_string(index=False))\n",
                "print(f\"\\n   VIF < 5: ‚úÖ Kh√¥ng c√≥ v·∫•n ƒë·ªÅ\")\n",
                "print(f\"   VIF 5-10: ‚ö†Ô∏è C·∫ßn xem x√©t\")\n",
                "print(f\"   VIF > 10: ‚ùå ƒêa c·ªông tuy·∫øn nghi√™m tr·ªçng\")\n",
                "\n",
                "# Full summary\n",
                "print(f\"\\nüìã FULL REGRESSION SUMMARY:\")\n",
                "print(m1.summary())\n",
                "\n",
                "# ============================================================\n",
                "# REGRESSION 2: Psychological Factors ‚Üí Attitudinal Loyalty\n",
                "# ============================================================\n",
                "\n",
                "print(\"\\n\" + \"-\"*80)\n",
                "print(\"üìä REGRESSION 2: Psychological Factors ‚Üí Attitudinal Loyalty\")\n",
                "print(\"-\"*80)\n",
                "\n",
                "# Bi·∫øn ƒë·ªôc l·∫≠p: Psychological responses\n",
                "X2_vars = ['TRUST', 'CONV', 'ENJ', 'SC']\n",
                "X2 = df[X2_vars]\n",
                "\n",
                "# Th√™m constant\n",
                "X2_const = sm.add_constant(X2)\n",
                "\n",
                "# Ch·∫°y OLS\n",
                "m2 = sm.OLS(y, X2_const).fit()\n",
                "\n",
                "print(f\"\\nüìà K·∫æT QU·∫¢ MODEL 2:\")\n",
                "print(f\"   R¬≤ = {m2.rsquared:.4f}\")\n",
                "print(f\"   Adjusted R¬≤ = {m2.rsquared_adj:.4f}\")\n",
                "print(f\"   F-statistic = {m2.fvalue:.4f} (p = {m2.f_pvalue:.4f})\")\n",
                "\n",
                "print(f\"\\n   Coefficients:\")\n",
                "for var in ['const'] + X2_vars:\n",
                "    coef = m2.params[var]\n",
                "    pval = m2.pvalues[var]\n",
                "    sig = \"***\" if pval < 0.001 else \"**\" if pval < 0.01 else \"*\" if pval < 0.05 else \"\"\n",
                "    print(f\"     {var:8s}: {coef:7.4f}  (p = {pval:.4f}) {sig}\")\n",
                "\n",
                "print(f\"\\n   Ghi ch√∫: *** p<0.001, ** p<0.01, * p<0.05\")\n",
                "\n",
                "# VIF Check\n",
                "print(f\"\\n   üîç VIF (Multicollinearity Check):\")\n",
                "vif_data2 = pd.DataFrame()\n",
                "vif_data2[\"Variable\"] = X2_vars\n",
                "vif_data2[\"VIF\"] = [variance_inflation_factor(X2.values, i) for i in range(len(X2_vars))]\n",
                "print(vif_data2.to_string(index=False))\n",
                "\n",
                "# Full summary\n",
                "print(f\"\\nüìã FULL REGRESSION SUMMARY:\")\n",
                "print(m2.summary())\n",
                "\n",
                "# ============================================================\n",
                "# SO S√ÅNH 2 MODELS\n",
                "# ============================================================\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"üìä SO S√ÅNH 2 MODELS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "comparison = pd.DataFrame({\n",
                "    'Model': ['Model 1: Platform', 'Model 2: Psychology'],\n",
                "    'R¬≤': [m1.rsquared, m2.rsquared],\n",
                "    'Adj. R¬≤': [m1.rsquared_adj, m2.rsquared_adj],\n",
                "    'F-stat': [m1.fvalue, m2.fvalue],\n",
                "    'Prob(F)': [m1.f_pvalue, m2.f_pvalue]\n",
                "})\n",
                "\n",
                "print(\"\\n\" + comparison.to_string(index=False))\n",
                "\n",
                "# L∆∞u k·∫øt qu·∫£\n",
                "results1 = pd.DataFrame({\n",
                "    'Variable': m1.params.index,\n",
                "    'Coefficient': m1.params.values,\n",
                "    'Std Error': m1.bse.values,\n",
                "    'p-value': m1.pvalues.values\n",
                "})\n",
                "results1.to_csv('regression1_results.csv', index=False)\n",
                "\n",
                "results2 = pd.DataFrame({\n",
                "    'Variable': m2.params.index,\n",
                "    'Coefficient': m2.params.values,\n",
                "    'Std Error': m2.bse.values,\n",
                "    'p-value': m2.pvalues.values\n",
                "})\n",
                "results2.to_csv('regression2_results.csv', index=False)\n",
                "\n",
                "print(f\"\\nüíæ ƒê√£ l∆∞u:\")\n",
                "print(f\"   - regression1_results.csv\")\n",
                "print(f\"   - regression2_results.csv\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"‚úÖ HO√ÄN TH√ÄNH T·∫§T C·∫¢ PH√ÇN T√çCH!\")\n",
                "print(\"=\"*80)"
            ],
            "metadata": {
                "id": "regression"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "\n",
                "## üéâ K·∫æT QU·∫¢\n",
                "\n",
                "Sau khi ch·∫°y 3 cells tr√™n, b·∫°n ƒë√£ c√≥:\n",
                "\n",
                "### ‚úÖ Files ƒë∆∞·ª£c t·∫°o:\n",
                "1. `onlinebuy_cleaned.csv` - D·ªØ li·ªáu ƒë√£ l√†m s·∫°ch\n",
                "2. `factor_loadings.csv` - K·∫øt qu·∫£ Factor Analysis\n",
                "3. `regression1_results.csv` - K·∫øt qu·∫£ Regression 1\n",
                "4. `regression2_results.csv` - K·∫øt qu·∫£ Regression 2\n",
                "\n",
                "### ‚úÖ K·∫øt qu·∫£ in ra:\n",
                "- S·ªë m·∫´u b·ªã lo·∫°i b·ªè\n",
                "- KMO Score\n",
                "- S·ªë factors t·ªëi ∆∞u\n",
                "- Factor loadings matrix\n",
                "- R¬≤ cho 2 models\n",
                "- Coefficients v·ªõi p-values\n",
                "- VIF scores\n",
                "\n",
                "### üìù B∆∞·ªõc ti·∫øp theo:\n",
                "1. Copy k·∫øt qu·∫£ v√†o b√°o c√°o Word\n",
                "2. T√¨m 15+ references\n",
                "3. Vi·∫øt b√°o c√°o 4,000 t·ª´\n",
                "4. Submit!\n",
                "\n",
                "---\n",
                "\n",
                "**üí™ GOOD LUCK!**"
            ],
            "metadata": {
                "id": "conclusion"
            }
        }
    ]
}