#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PHÃ‚N TÃCH HOÃ€N CHá»ˆNH - MDA2025
CÃ¡c yáº¿u tá»‘ quyáº¿t Ä‘á»‹nh lÃ²ng trung thÃ nh cá»§a ngÆ°á»i tiÃªu dÃ¹ng trÃªn TMÄT

Bao gá»“m:
1. Data Cleaning
2. Factor Analysis
3. Regression Analysis

Author: Antigravity AI Assistant
Date: 9/12/2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

print("="*80)
print("PHÃ‚N TÃCH MARKETING - MDA2025")
print("Báº¯t Ä‘áº§u phÃ¢n tÃ­ch...")
print("="*80)

# ============================================================
# 1. Äá»ŒC Dá»® LIá»†U
# ============================================================

print("\nğŸ“‚ BÆ¯á»šC 1: Äá»ŒC Dá»® LIá»†U")
print("-"*80)

try:
    df = pd.read_csv("onlinebuy.csv")
    print(f"âœ… Äá»c dá»¯ liá»‡u thÃ nh cÃ´ng!")
    print(f"   KÃ­ch thÆ°á»›c: {df.shape} (rows, columns)")
except FileNotFoundError:
    print("âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y file 'onlinebuy.csv'")
    print("   Vui lÃ²ng Ä‘áº£m báº£o file CSV náº±m cÃ¹ng thÆ° má»¥c vá»›i script nÃ y.")
    exit(1)

# Danh sÃ¡ch cÃ¡c cá»™t Likert
likert_cols = [
    'int1','int2','inf1','inf2','inf3','ve1','ve2','ve3','nvse1','nvse2',
    'trust1','trust2','trust3','conv1','conv2','conv3','conv4',
    'enj1','enj2','enj3','sc1','sc2','al1','al2','al3'
]

# ============================================================
# 2. DATA CLEANING - LOáº I Bá» Dá»® LIá»†U KHÃ”NG Há»¢P Lá»†
# ============================================================

print("\nğŸ§¹ BÆ¯á»šC 2: DATA CLEANING")
print("-"*80)

def check_invalid_responses(row, cols):
    """
    Kiá»ƒm tra xem má»™t row cÃ³ dá»¯ liá»‡u khÃ´ng há»£p lá»‡ khÃ´ng
    
    TiÃªu chÃ­ khÃ´ng há»£p lá»‡:
    1. Táº¥t cáº£ giÃ¡ trá»‹ giá»‘ng nhau
    2. CÃ³ â‰¥10 giÃ¡ trá»‹ liÃªn tiáº¿p giá»‘ng nhau
    
    Returns:
        tuple: (is_invalid: bool, reason: str)
    """
    values = row[cols].values
    
    # TiÃªu chÃ­ 1: Táº¥t cáº£ giá»‘ng nhau
    if len(set(values)) == 1:
        return True, "all_same"
    
    # TiÃªu chÃ­ 2: 10 giÃ¡ trá»‹ liÃªn tiáº¿p giá»‘ng nhau
    max_consecutive = 1
    current_consecutive = 1
    
    for i in range(1, len(values)):
        if values[i] == values[i-1]:
            current_consecutive += 1
            max_consecutive = max(max_consecutive, current_consecutive)
        else:
            current_consecutive = 1
    
    if max_consecutive >= 10:
        return True, f"consecutive_{max_consecutive}"
    
    return False, "valid"

# TÃ¬m rows khÃ´ng há»£p lá»‡
print("ğŸ” Kiá»ƒm tra dá»¯ liá»‡u khÃ´ng há»£p lá»‡...")
invalid_rows = []
invalid_reasons = []

for idx, row in df.iterrows():
    is_invalid, reason = check_invalid_responses(row, likert_cols)
    if is_invalid:
        invalid_rows.append(idx)
        invalid_reasons.append(reason)

# BÃ¡o cÃ¡o káº¿t quáº£
print(f"\nğŸ“Š Káº¾T QUáº¢ KIá»‚M TRA:")
print(f"   Tá»•ng sá»‘ máº«u: {len(df)}")
print(f"   Sá»‘ máº«u khÃ´ng há»£p lá»‡: {len(invalid_rows)} ({len(invalid_rows)/len(df)*100:.1f}%)")

if len(invalid_rows) > 0:
    # Thá»‘ng kÃª theo loáº¡i lá»—i
    reason_counts = Counter(invalid_reasons)
    
    print(f"\n   PhÃ¢n loáº¡i lá»—i:")
    for reason, count in reason_counts.items():
        print(f"     - {reason}: {count} máº«u")
    
    # Hiá»ƒn thá»‹ vÃ­ dá»¥
    print(f"\n   ğŸ” 5 vÃ­ dá»¥ Ä‘áº§u tiÃªn:")
    for i, (idx, reason) in enumerate(zip(invalid_rows[:5], invalid_reasons[:5])):
        print(f"     Row {idx}: {reason}")

# Loáº¡i bá»
df_clean = df.drop(invalid_rows).reset_index(drop=True)

print(f"\nâœ… Káº¾T QUáº¢ SAU KHI LÃ€M Sáº CH:")
print(f"   ÄÃ£ loáº¡i bá»: {len(invalid_rows)} máº«u")
print(f"   CÃ²n láº¡i: {len(df_clean)} máº«u ({len(df_clean)/len(df)*100:.1f}%)")

# LÆ°u dá»¯ liá»‡u sáº¡ch
df_clean.to_csv("onlinebuy_cleaned.csv", index=False)
print(f"\nğŸ’¾ ÄÃ£ lÆ°u: onlinebuy_cleaned.csv")

# Cáº­p nháº­t df
df = df_clean.copy()

# ============================================================
# 3. FACTOR ANALYSIS
# ============================================================

print("\n\nğŸ“Š BÆ¯á»šC 3: FACTOR ANALYSIS")
print("-"*80)

try:
    from factor_analyzer import FactorAnalyzer
    from factor_analyzer.factor_analyzer import calculate_kmo, calculate_bartlett_sphericity
    
    print("âœ… ThÆ° viá»‡n factor-analyzer Ä‘Ã£ cÃ³ sáºµn")
except ImportError:
    print("âš ï¸  Äang cÃ i Ä‘áº·t thÆ° viá»‡n factor-analyzer...")
    import subprocess
    subprocess.check_call(['pip', 'install', 'factor-analyzer', '-q'])
    from factor_analyzer import FactorAnalyzer
    from factor_analyzer.factor_analyzer import calculate_kmo, calculate_bartlett_sphericity
    print("âœ… ÄÃ£ cÃ i Ä‘áº·t thÃ nh cÃ´ng!")

# 3.1. KMO & Bartlett's Test
print("\nğŸ” 3.1. KMO & Bartlett's Test")

kmo_all, kmo_model = calculate_kmo(df[likert_cols])

print(f"\n   KMO Score: {kmo_model:.3f}")
if kmo_model >= 0.9:
    print(f"   â†’ âœ… Tuyá»‡t vá»i (â‰¥0.9)")
elif kmo_model >= 0.8:
    print(f"   â†’ âœ… Ráº¥t tá»‘t (â‰¥0.8)")
elif kmo_model >= 0.7:
    print(f"   â†’ âœ… Trung bÃ¬nh (â‰¥0.7)")
elif kmo_model >= 0.6:
    print(f"   â†’ âš ï¸  Vá»«a pháº£i (â‰¥0.6)")
else:
    print(f"   â†’ âŒ KhÃ´ng phÃ¹ há»£p (<0.6)")

# Bartlett's Test
chi_square_value, p_value = calculate_bartlett_sphericity(df[likert_cols])

print(f"\n   Bartlett's Test:")
print(f"     Chi-square: {chi_square_value:.2f}")
print(f"     p-value: {p_value:.4f}")
if p_value < 0.05:
    print(f"   â†’ âœ… CÃ³ Ã½ nghÄ©a thá»‘ng kÃª (p < 0.05)")
    print(f"   â†’ âœ… Dá»¯ liá»‡u phÃ¹ há»£p cho Factor Analysis")
else:
    print(f"   â†’ âŒ KhÃ´ng cÃ³ Ã½ nghÄ©a thá»‘ng kÃª (p â‰¥ 0.05)")

# 3.2. XÃ¡c Ä‘á»‹nh sá»‘ nhÃ¢n tá»‘ tá»‘i Æ°u
print("\nğŸ” 3.2. XÃ¡c Ä‘á»‹nh sá»‘ nhÃ¢n tá»‘ tá»‘i Æ°u")

fa_test = FactorAnalyzer(n_factors=len(likert_cols), rotation=None)
fa_test.fit(df[likert_cols])

ev, v = fa_test.get_eigenvalues()

print(f"\n   Eigenvalues (Kaiser Criterion: > 1.0):")
n_factors_optimal = sum(ev > 1.0)
for i, eigenvalue in enumerate(ev[:10], 1):
    marker = "âœ…" if eigenvalue > 1.0 else "  "
    print(f"   {marker} Factor {i}: {eigenvalue:.3f}")

print(f"\n   ğŸ’¡ Sá»‘ nhÃ¢n tá»‘ tá»‘i Æ°u: {n_factors_optimal}")

# 3.3. Cháº¡y Factor Analysis vá»›i Varimax rotation
print(f"\nğŸ” 3.3. Factor Analysis vá»›i Varimax Rotation")

fa = FactorAnalyzer(n_factors=n_factors_optimal, rotation='varimax')
fa.fit(df[likert_cols])

loadings = fa.loadings_

# Táº¡o DataFrame
loadings_df = pd.DataFrame(
    loadings,
    index=likert_cols,
    columns=[f'Factor{i+1}' for i in range(n_factors_optimal)]
)

print(f"\n   ğŸ“‹ Factor Loadings (chá»‰ hiá»ƒn thá»‹ |loading| â‰¥ 0.4):")
for col in loadings_df.columns:
    print(f"\n   {col}:")
    high_loadings = loadings_df[col][abs(loadings_df[col]) >= 0.4].sort_values(ascending=False)
    if len(high_loadings) > 0:
        for var, loading in high_loadings.items():
            print(f"     {var:8s}: {loading:6.3f}")
    else:
        print(f"     (KhÃ´ng cÃ³ biáº¿n nÃ o cÃ³ loading â‰¥ 0.4)")

# Variance Explained
variance = fa.get_factor_variance()
print(f"\n   ğŸ“Š PhÆ°Æ¡ng sai giáº£i thÃ­ch:")
print(f"     Tá»•ng: {variance[2][-1]*100:.1f}%")

# LÆ°u káº¿t quáº£
loadings_df.to_csv("factor_loadings.csv")
print(f"\nğŸ’¾ ÄÃ£ lÆ°u: factor_loadings.csv")

# ============================================================
# 4. REGRESSION ANALYSIS
# ============================================================

print("\n\nğŸ“ˆ BÆ¯á»šC 4: REGRESSION ANALYSIS")
print("-"*80)

try:
    import statsmodels.api as sm
    from statsmodels.stats.outliers_influence import variance_inflation_factor
    print("âœ… ThÆ° viá»‡n statsmodels Ä‘Ã£ cÃ³ sáºµn")
except ImportError:
    print("âš ï¸  Äang cÃ i Ä‘áº·t thÆ° viá»‡n statsmodels...")
    import subprocess
    subprocess.check_call(['pip', 'install', 'statsmodels', '-q'])
    import statsmodels.api as sm
    from statsmodels.stats.outliers_influence import variance_inflation_factor
    print("âœ… ÄÃ£ cÃ i Ä‘áº·t thÃ nh cÃ´ng!")

# Táº¡o cÃ¡c biáº¿n aggregate
print("\nğŸ”§ Táº¡o cÃ¡c biáº¿n aggregate...")

df['INT'] = df[['int1','int2']].mean(axis=1)
df['INF'] = df[['inf1','inf2','inf3']].mean(axis=1)
df['VE'] = df[['ve1','ve2','ve3']].mean(axis=1)
df['NVSE'] = df[['nvse1','nvse2']].mean(axis=1)
df['TRUST'] = df[['trust1','trust2','trust3']].mean(axis=1)
df['CONV'] = df[['conv1','conv2','conv3','conv4']].mean(axis=1)
df['ENJ'] = df[['enj1','enj2','enj3']].mean(axis=1)
df['SC'] = df[['sc1','sc2']].mean(axis=1)
df['AL'] = df[['al1','al2','al3']].mean(axis=1)

print("âœ… ÄÃ£ táº¡o 9 biáº¿n aggregate")

# 4.1. Regression 1: Platform Features â†’ Attitudinal Loyalty
print("\nğŸ“Š 4.1. REGRESSION 1: Platform Features â†’ Attitudinal Loyalty")
print("-"*60)

X1_vars = ['INT', 'INF', 'VE', 'NVSE']
X1 = df[X1_vars]
y = df['AL']

X1_with_const = sm.add_constant(X1)
model1 = sm.OLS(y, X1_with_const).fit()

print(f"\n   RÂ² = {model1.rsquared:.4f}")
print(f"   Adjusted RÂ² = {model1.rsquared_adj:.4f}")
print(f"   F-statistic = {model1.fvalue:.4f} (p = {model1.f_pvalue:.4f})")

print(f"\n   Coefficients:")
results1 = pd.DataFrame({
    'Variable': model1.params.index,
    'Coefficient': model1.params.values,
    'p-value': model1.pvalues.values,
    'Sig': ['***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else '' 
            for p in model1.pvalues.values]
})
print(results1.to_string(index=False))
print(f"\n   Ghi chÃº: *** p<0.001, ** p<0.01, * p<0.05")

# VIF check
print(f"\n   ğŸ” VIF (Multicollinearity Check):")
vif_data1 = pd.DataFrame()
vif_data1["Variable"] = X1_vars
vif_data1["VIF"] = [variance_inflation_factor(X1.values, i) for i in range(len(X1_vars))]
print(vif_data1.to_string(index=False))

# 4.2. Regression 2: Psychological Factors â†’ Attitudinal Loyalty
print("\n\nğŸ“Š 4.2. REGRESSION 2: Psychological Factors â†’ Attitudinal Loyalty")
print("-"*60)

X2_vars = ['TRUST', 'CONV', 'ENJ', 'SC']
X2 = df[X2_vars]

X2_with_const = sm.add_constant(X2)
model2 = sm.OLS(y, X2_with_const).fit()

print(f"\n   RÂ² = {model2.rsquared:.4f}")
print(f"   Adjusted RÂ² = {model2.rsquared_adj:.4f}")
print(f"   F-statistic = {model2.fvalue:.4f} (p = {model2.f_pvalue:.4f})")

print(f"\n   Coefficients:")
results2 = pd.DataFrame({
    'Variable': model2.params.index,
    'Coefficient': model2.params.values,
    'p-value': model2.pvalues.values,
    'Sig': ['***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else '' 
            for p in model2.pvalues.values]
})
print(results2.to_string(index=False))
print(f"\n   Ghi chÃº: *** p<0.001, ** p<0.01, * p<0.05")

# VIF check
print(f"\n   ğŸ” VIF (Multicollinearity Check):")
vif_data2 = pd.DataFrame()
vif_data2["Variable"] = X2_vars
vif_data2["VIF"] = [variance_inflation_factor(X2.values, i) for i in range(len(X2_vars))]
print(vif_data2.to_string(index=False))

# So sÃ¡nh 2 models
print("\n\nğŸ“Š SO SÃNH 2 MODELS:")
print("-"*60)

comparison = pd.DataFrame({
    'Model': ['Model 1: Platform', 'Model 2: Psychology'],
    'RÂ²': [model1.rsquared, model2.rsquared],
    'Adj. RÂ²': [model1.rsquared_adj, model2.rsquared_adj],
    'F-statistic': [model1.fvalue, model2.fvalue],
    'Prob (F)': [model1.f_pvalue, model2.f_pvalue]
})
print(comparison.to_string(index=False))

# LÆ°u káº¿t quáº£
results1.to_csv("regression1_results.csv", index=False)
results2.to_csv("regression2_results.csv", index=False)
print(f"\nğŸ’¾ ÄÃ£ lÆ°u:")
print(f"   - regression1_results.csv")
print(f"   - regression2_results.csv")

# ============================================================
# 5. TÃ“M Táº®T Káº¾T QUáº¢
# ============================================================

print("\n\n" + "="*80)
print("ğŸ¯ TÃ“M Táº®T Káº¾T QUáº¢ PHÃ‚N TÃCH")
print("="*80)

print(f"\n1ï¸âƒ£ DATA CLEANING:")
print(f"   âœ… ÄÃ£ loáº¡i bá» {len(invalid_rows)} máº«u khÃ´ng há»£p lá»‡")
print(f"   âœ… CÃ²n láº¡i {len(df_clean)} máº«u sá»­ dá»¥ng cho phÃ¢n tÃ­ch")

print(f"\n2ï¸âƒ£ FACTOR ANALYSIS:")
print(f"   âœ… KMO Score: {kmo_model:.3f}")
print(f"   âœ… Sá»‘ nhÃ¢n tá»‘ tá»‘i Æ°u: {n_factors_optimal}")
print(f"   âœ… PhÆ°Æ¡ng sai giáº£i thÃ­ch: {variance[2][-1]*100:.1f}%")

print(f"\n3ï¸âƒ£ REGRESSION 1 (Platform â†’ Loyalty):")
print(f"   âœ… RÂ² = {model1.rsquared:.4f}")
print(f"   âœ… Significant variables:")
for var in X1_vars:
    if model1.pvalues[var] < 0.05:
        coef = model1.params[var]
        print(f"      â€¢ {var}: {coef:+.4f} (p < 0.05)")

print(f"\n4ï¸âƒ£ REGRESSION 2 (Psychology â†’ Loyalty):")
print(f"   âœ… RÂ² = {model2.rsquared:.4f}")
print(f"   âœ… Significant variables:")
for var in X2_vars:
    if model2.pvalues[var] < 0.05:
        coef = model2.params[var]
        print(f"      â€¢ {var}: {coef:+.4f} (p < 0.05)")

print("\n\nğŸ“ FILES ÄÃƒ Táº O:")
print("   âœ… onlinebuy_cleaned.csv - Dá»¯ liá»‡u sau khi lÃ m sáº¡ch")
print("   âœ… factor_loadings.csv - Káº¿t quáº£ Factor Analysis")
print("   âœ… regression1_results.csv - Káº¿t quáº£ Regression 1")
print("   âœ… regression2_results.csv - Káº¿t quáº£ Regression 2")

print("\n\n" + "="*80)
print("ğŸ‰ HOÃ€N THÃ€NH Táº¤T Cáº¢ PHÃ‚N TÃCH!")
print("="*80)
print("\nğŸ“– BÆ¯á»šC TIáº¾P THEO:")
print("   1. Xem cÃ¡c file CSV Ä‘Ã£ táº¡o Ä‘á»ƒ láº¥y káº¿t quáº£")
print("   2. Copy káº¿t quáº£ vÃ o bÃ¡o cÃ¡o Word")
print("   3. TÃ¬m 15+ references")
print("   4. Viáº¿t bÃ¡o cÃ¡o 4,000 tá»«")
print("\nğŸ’ª GOOD LUCK!\n")
